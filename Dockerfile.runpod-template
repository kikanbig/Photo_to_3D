# Use RunPod's pre-built PyTorch template
FROM runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04

# Set working directory
WORKDIR /workspace

# Install only missing dependencies for TRELLIS
RUN pip install --no-cache-dir \
    easydict>=1.9.0 \
    einops>=0.7.0 \
    omegaconf>=2.3.0 \
    tqdm>=4.64.0 \
    runpod>=1.0.0

# Clone TRELLIS repository
RUN git clone https://github.com/microsoft/TRELLIS.git /workspace/trellis_source

# Try to install TRELLIS dependencies if they exist
WORKDIR /workspace/trellis_source
RUN if [ -f "requirements.txt" ]; then pip install -r requirements.txt || echo "Some TRELLIS deps failed, continuing..."; fi
RUN if [ -f "setup.py" ]; then pip install -e . || echo "TRELLIS setup failed, continuing..."; fi

# Copy our ML server code
WORKDIR /workspace
COPY ml_server/ .

# Set Python path
ENV PYTHONPATH=/workspace:/workspace/trellis_source
ENV CUDA_VISIBLE_DEVICES=0

# Expose port for RunPod
EXPOSE 8000

# Start command
CMD ["python", "handler.py"]
